{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# IBM Code Day - Data Science - Hands-on\n*Paso a paso*\n\nEn este *notebook* se describe el paso a paso del hands-on \"Data Science de la A a la Z con IBM Watson Studio\".\n\nEste *notebook* puede ser descargado y subido como un *asset* en **Watson Studio**.", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## Autor y licencia\nBruno Gonz\u00e1lez es Ingeniero en Computaci\u00f3n, especializado en datos, y trabaja como *Lead Data Engineer* en <a href=\"http://www.idatha.com\">IDATHA</a>.\n<br><br>\n**LinkedIn:** https://www.linkedin.com/in/brunogonzalezms<br>\n**Twitter:** https://twitter.com/brunoo_gonzalez\n\nEste *notebook* y el c\u00f3digo que contiene est\u00e1 liberado bajo los t\u00e9rminos de licencia de <a href=\"https://opensource.org/licenses/MIT\">MIT License</a>.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Tabla de contenidos\n1. [Objetivo](#1.-Objetivo)\n2. [Preparaci\u00f3n del ambiente](#2.-Preparaci\u00f3n-del-ambiente)<br>\n    2.1. [Precondiciones](#2.1-Precondiciones)<br>\n    2.2. [Creaci\u00f3n del servicio Node-Red](#2.2-Creaci\u00f3n-del-servicio-Node-Red)<br>\n    2.3. [Creaci\u00f3n de servicios](#2.3-Creaci\u00f3n-de-servicios)<br>\n    2.4. [Creaci\u00f3n del proyecto](#2.4-Creaci\u00f3n-del-proyecto)\n3. [Adquisici\u00f3n de datos](#3.-Adquisici\u00f3n-de-datos)<br>\n    3.1. [Configuraci\u00f3n servicio Node-Red](#3.1-Configuraci\u00f3n-servicio-Node-Red)<br>\n    3.2. [Creaci\u00f3n del flujo](#3.2-Creaci\u00f3n-del-flujo)<br>\n    3.3. [Verificaci\u00f3n de flujo](#3.3-Verificaci\u00f3n-de-flujo)\n4. [Ingesta](#4.-Ingesta)<br>\n    4.1. [Copia del notebook](#4.1-Copia-del-notebook)<br>\n    4.2. [Ejecuci\u00f3n del notebook](#4.2-Ejecuci\u00f3n-del-notebook)\n5. [Descubrimiento](#5.-Descubrimiento)<br>\n    5.1 [Descarga archivos desde Object Storage](#5.1-Descarga-archivos-desde-Object-Storage)<br>\n    5.2 [Carga de archivos como Assets](#5.2-Carga-de-archivos-como-Assets)<br>\n    5.3 [Uso de Data Refinery](#5.3-Uso-de-Data-Refinery)\n6. [An\u00e1lisis y limpieza](#6.-An\u00e1lisis-y-limpieza)<br>\n    6.1. [Creaci\u00f3n del notebook](#6.1-Creaci\u00f3n-del-notebook)<br>\n    6.2. [Carga de datos en notebook](#6.2-Carga-de-datos-en-notebook)<br>\n    6.3. [An\u00e1lisis y limpieza de datos](#6.3-An\u00e1lisis-y-limpieza-de-datos)\n7. [Transformaci\u00f3n y enriquecimiento](#7.-Transformaci\u00f3n-y-enriquecimiento)<br>\n    7.1. [Enriquecimiento con Natural Language Understanding](#7.1-Enriquecimiento-con-Natural-Language-Understanding)\n8. [Modelado y puesta en producci\u00f3n](#8.-Modelado-y-puesta-en-producci\u00f3n)\n9. [Visualizaci\u00f3n](#9.-Visualizaci\u00f3n)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## 1. Objetivo", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "El objetivo principal de este hands-on es conocer Watson Studio como herramienta de procesamiento, an\u00e1lisis y generaci\u00f3n de modelos de Machine Learning, utilizando diferentes servicios de IBM Cloud.\n\nTrabajaremos en un caso pr\u00e1ctico utilizando Twitter, NodeRed, Cloudant, Watson Studio y herramientas cognitivas de Watson, para extraer *insights* de opiniones de usuarios acerca de un tema.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## 2. Preparaci\u00f3n del ambiente", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 2.1 Precondiciones\nPara comenzar este hands-on se requiere:\n1. Contar con una cuenta de Twitter y una aplicaci\u00f3n creada en https://apps.twitter.com/.\n2. Contar con una cuenta de [IBM Cloud](https://www.ibm.com/cloud/).\n    - Se puede aplicar a un c\u00f3digo de promoci\u00f3n enrol\u00e1ndose en *Cognitive Class*: https://cognitiveclass.ai/ibm-cloud-promotion/\n3. Contar con una cuenta en [Watson Studio](http://datascience.ibm.com/).\n    - Si la cuenta de IBM Cloud estaba inactiva, es mejor crear otra cuenta con un correo electr\u00f3nico nuevo.\n    - Si no se est\u00e1 registrado en Watson Studio, cliquear el bot\u00f3n *Sign Up* en la esquina superior derecha de https://datascience.ibm.com/.\n\nLuego de completar el *Sign Up*, se debe ver una p\u00e1gina como la siguiente:\n![watson-studio-initial.png](https://raw.githubusercontent.com/brunoogonzalez/IBMCodeMVD/master/watson-studio-initial.png)", 
            "cell_type": "markdown", 
            "attachments": {}, 
            "metadata": {}
        }, 
        {
            "source": "### 2.2 Creaci\u00f3n del servicio Node-Red\n1. Navegar a la URL https://console.bluemix.net/dashboard/apps/.\n2. Cliquear el bot\u00f3n *Crear recurso* de la esquina superior derecha.\n3. Utilizar la b\u00fasqueda con la palabra clave *node-red*.\n4. Cliquear el servicio *Node-RED Starter*.\n5. Especificar el nombre en el campo *Nombre de la app*.\n6. Verificar que *Cloudant NoSQL DB* tenga seleccionado el plan *Lite*.\n7. Cliquear el bot\u00f3n *Crear*.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 2.3 Creaci\u00f3n de servicios", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Watson Services\n1. En el men\u00fa *Services*, cliquear la opci\u00f3n *Watson Services*.\n2. Cliquear el bot\u00f3n *Add service* de la esquina superior derecha.\n3. Cliquear el bot\u00f3n *Add*, luego el bot\u00f3n *Create*, y para finalizar el bot\u00f3n *Confirm* de los servicios: *Machine Learning*, *Natural Language Understanding* y *Visual Recognition*.<br>\n**Nota:** Para todos estos servicios elegir el plan *Lite*.\n![ibm-watson-services.png](https://raw.githubusercontent.com/brunoogonzalez/IBMCodeMVD/master/ibm-watson-services.png)", 
            "cell_type": "markdown", 
            "attachments": {}, 
            "metadata": {}
        }, 
        {
            "source": "#### Compute Services\n1. En el men\u00fa *Services*, cliquear la opci\u00f3n *Compute Services*.\n2. Cliquear el bot\u00f3n *Add service* de la esquina superior derecha.\n3. Cliquear el bot\u00f3n *Add*, luego el bot\u00f3n *Create*, y para finalizar el bot\u00f3n *Confirm* del servicio *IBM Cognos Dashboard Embedded* (elegir el plan *Lite*).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 2.4 Creaci\u00f3n del proyecto\n#### Creaci\u00f3n\n1. En el men\u00fa *Projects*, cliquear la opci\u00f3n *View All Projects*.\n2. Cliquear el bot\u00f3n *New* de la esquina superior derecha.\n3. Especificar un nombre en el campo *Name*.\n4. Si no est\u00e1 creada, crear un *storage* haciendo clic en el bot\u00f3n *Add* que se encuentra a la derecha, bajo el t\u00edtulo *Define storage* (especificar plan *Lite* para el *Cloud Object Storage* a crear).\n5. Una vez creado el *Cloud Object Storage*, cliquear el bot\u00f3n *Refresh*.\n6. Dejar seleccionada la opci\u00f3n *Restrict who can be a collaborator*.\n7. Cliquear el bot\u00f3n *Create* para crear el proyecto.\n\n#### Configuraci\u00f3n\n1. Una vez creado el proyecto, dirigirse a la solapa *Settings*.\n2. Navegar hasta el t\u00edtulo *Associated services*.\n3. Cliquear el bot\u00f3n *Add service* y luego cliquear la opci\u00f3n *Spark*.\n    1. En la solapa *New*, seleccionar la opci\u00f3n *Lite*.\n    2. Cliquar el bot\u00f3n *Create* y luego *Confirm*.\n5. Cliquear nuevamente el bot\u00f3n *Add service* y luego cliquear la opci\u00f3n *Dashboard*.\n    1. En la solapa *Existing*, desplegar la lista *Existing Service Instance*.\n    2. Seleccionar el servicio creado en [Compute Services](#Compute-Services).\n    3. Cliquear el bot\u00f3n *Select*.\n6. Cliquear nuevamente el bot\u00f3n *Add service* y luego cliquear la opci\u00f3n *Watson*.\n    1. Cliquear el bot\u00f3n *Add* del servicio *Visual Recognition*.\n    2. En la solapa *Existing*, desplegar la lista *Existing Service Instance*.\n    3. Seleccionar el servicio creado en [Watson Services](#Watson-Services).\n    4. Cliquear el bot\u00f3n *Select*.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## 3. Adquisici\u00f3n de datos", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 3.1 Configuraci\u00f3n servicio Node-Red\n1. Ingresar al *dashboard* de IBM Cloud: https://console.bluemix.net/dashboard/apps/.\n2. Seleccionar aplicaci\u00f3n creada en [Creaci\u00f3n del servicio Node-Red](#2.2-Creaci\u00f3n-del-servicio-Node-Red).\n3. Cliquear en *Visitar URL de app*.\n4. Cliquear el bot\u00f3n *Next*.\n5. Especificar *Username* y *Password* y cliquear el bot\u00f3n *Next*.<br>\n**Importante:** anotar el usuario y contrase\u00f1a para ser utilizados en el paso 8.\n6. Cliquear el bot\u00f3n *Next* y luego el bot\u00f3n *Finish*.\n7. Una vez terminada la configuraci\u00f3n, cliquear el bot\u00f3n *Go to your Node-RED flow editor*.\n8. Especificar *Username* y *Password* y cliquear el bot\u00f3n *Login*.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 3.2 Creaci\u00f3n del flujo\nUna vez dentro de la aplicaci\u00f3n de Node-Red:\n1. Nodo Twitter:\n    1. Utilizar el cuadro de b\u00fasqueda de la esquina superior izquierda.\n    2. Ingresar el criterio de b\u00fasqueda *twitter*.\n    3. Seleccionar y arrastrar al flujo el nodo *Twitter in* (el que tiene el logo de Twitter a la izquierda).\n    4. Hacer doble clic sobre el nodo.\n    5. Hacer clic en el bot\u00f3n del l\u00e1piz del campo *Twitter ID*.\n    6. Completar las credenciales con las credenciales de la app de Twitter, especificadas en la solapa *Keys and Access Tokens* dentro de la configuraci\u00f3n de la aplicaci\u00f3n (https://apps.twitter.com).\n    7. En el campo *Search*, seleccionar la opci\u00f3n *all public tweets*.\n    8. En el campo *for*, especificar el criterio de b\u00fasqueda: **ibmcodemvd**.\n    9. Cliquear el bot\u00f3n *Done*.\n2. Nodo Cloudant:\n    1. Utilizar el cuadro de b\u00fasqueda de la esquina superior izquierda.\n    2. Ingresar el criterio de b\u00fasqueda *cloudant*.\n    3. Seleccionar y arrastrar al flujo el nodo *Cloudant out* (el que tiene el logo de Cloudant a la derecha).\n    4. Hacer doble clic sobre el nodo.\n    5. En el campo *Database*, especificar el nombre de la base de datos: **tweets**.\n    6. Cliquear el bot\u00f3n *Done*.\n3. Partiendo desde la conexi\u00f3n del nodo *Twitter in*, crear una conexi\u00f3n hacia el nodo *Cloudant out*.<br>\nDeber\u00eda quedar similar a la siguiente imagen:\n![node-red-twitter.png](https://raw.githubusercontent.com/brunoogonzalez/IBMCodeMVD/master/node-red-twitter.png)\n4. Cliquear el bot\u00f3n *Deploy* de la esquina superior derecha.", 
            "cell_type": "markdown", 
            "attachments": {}, 
            "metadata": {}
        }, 
        {
            "source": "### 3.3 Verificaci\u00f3n de flujo\n1. Ingresar al *dashboard* de IBM Cloud: https://console.bluemix.net/dashboard/apps/.\n2. Bajo el t\u00edtulo *Servicios de Cloud Foundry*, seleccionar el servicio de *Cloudant*.\n3. Cliquear el bot\u00f3n *Launch Cloudant Dashboard*.\n4. Cliquear en el men\u00fa *Databases*.\n5. Verificar que la base de datos **tweets** est\u00e1 creada y tiene documentos.<br>\n**Nota:** En caso de no tener documentos, probar twitteando con el hashtag #IBMCodeMVD.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## 4. Ingesta", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 4.1 Copia del notebook\n1. Acceder a la URL del [notebook de ejemplo](https://dataplatform.ibm.com/analytics/notebooks/v2/79791822-7da9-4814-b655-391aec34b48f/view?access_token=bd640bbb524d2b52fe40d4a5ba2e233a22c66ef46f4b043001058585afc31998).\n2. Descargar el notebook haciendo clic en el bot\u00f3n de descarga de la esquina superior derecha.\n3. En el men\u00fa *Projects*, cliquear la opci\u00f3n del proyecto creado en [Creaci\u00f3n del proyecto](#2.4-Creaci\u00f3n-del-proyecto).\n4. Cliquear en la solapa *Assets*, y a la derecha del t\u00edtulo *Notebooks*, cliquear el bot\u00f3n *New notebook*.\n5. Cliquear en la opci\u00f3n *From file*.\n6. Cliquear en *Examinar* en el campo *Notebook file*.\n7. Especificar el nombre en el campo *Name*.\n8. Seleccionar el servicio de Spark creado en [Configuraci\u00f3n](#Configuraci\u00f3n) en el campo *Select runtime*.\n9. Cliquear el bot\u00f3n *Create Notebook*.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 4.2 Ejecuci\u00f3n del notebook\n1. En el men\u00fa *Projects*, cliquear la opci\u00f3n del proyecto creado en [Creaci\u00f3n del proyecto](#2.4-Creaci\u00f3n-del-proyecto).\n2. Cliquear el bot\u00f3n *Add to project* de la esquina superior derecha, y seleccionar la opci\u00f3n *Connection*\n3. Bajo el t\u00edtulo *Your service instances in IBM Cloud*, seleccionar la instancia de *Cloudant* creada junto con *Node-Red*.\n4. Cliquear el bot\u00f3n *Create*.\n5. Ingresar al notebook creado en [Creaci\u00f3n del notebook](#4.1-Creaci\u00f3n-del-notebook).\n6. En la tercera celda de c\u00f3digo, que tiene un comentario que dice: `The code was removed by DSX for sharing.`, ingresar las credenciales de *Cloudant*.\n    1. Hacer doble clic sobre la celda y borrar el comentario.\n    2. Seleccionar la opci\u00f3n *Data* dentro del notebook (bot\u00f3n con 1 y 0 en la esquina superior derecha del notebook).\n    3. Ingresar a la solapa *Connections*.\n    4. Cliquear el bot\u00f3n *Insert to code* del servicio de *Cloudant*.\n    5. Modificar el nombre de la variable creada para que tenga el nombre `credentials_1`.\n    6. Guardar el notebook utilizando el men\u00fa *File*, opci\u00f3n *Save*.\n7. Ejecutar la primera celda de c\u00f3digo que comienza con `import pixiedust` (la celda se ejecuta utilizando el bot\u00f3n *Run* de la barra de herramientas).\n8. Reiniciar el notebook utilizando el men\u00fa *Kernel*, opci\u00f3n *Restart* (confirmar el reinicio).\n9. En la primera celda de c\u00f3digo, luego del t\u00edtulo *Subida de datos a Object Storage*, que tiene un comentario que dice: `The code was removed by DSX for sharing.`, ingresar las credenciales de *Cloud Object Storage*.\n    1. Hacer doble clic sobre la celda y borrar el comentario.\n    2. Ingresar al *dashboard* de IBM Cloud: https://console.bluemix.net/dashboard/apps/.\n    3. Bajo el t\u00edtulo *Servicios*, cliquear el servicio de *Cloud Object Storage* creado con el proyecto de Watson Studio.\n    4. Cliquear el men\u00fa *Service credentials*.\n    5. Copiar todo el JSON de la credencial que corresponde al *Admin*.\n    6. Pegar el c\u00f3digo del JSON en la celda borrada y asignarlo a una variable de nombre `cos_credentials`.\n    7. Cliquear el men\u00fa *Buckets*.\n    8. Copiar el nombre del \u00fanico bucket que aparece.\n    8. En la tercera celda de c\u00f3digo, luego del t\u00edtulo *Subida de datos a Object Storage*, modificar el tercer par\u00e1metro de la funci\u00f3n `upload_file_cos` con el nombre correspondiente al bucket del *Cloud Object Storage* (reci\u00e9n copiado).\n10. Ejecutar todas las celdas utilizando el men\u00fa *Cell*, opci\u00f3n *Run All*.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## 5. Descubrimiento", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 5.1 Descarga archivos desde Object Storage\n1. Ingresar al *dashboard* de IBM Cloud: https://console.bluemix.net/dashboard/apps/.\n2. Bajo el t\u00edtulo *Servicios*, cliquear el servicio de *Cloud Object Storage* creado con el proyecto de Watson Studio.\n3. Cliquear en el men\u00fa *Buckets*.\n4. Cliquear el nombre del \u00fanico bucket que aparece.\n5. Buscar los objetos guardados por el notebook (archivos CSV) y descargarlos.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 5.2 Carga de archivos como Assets\n1. En el men\u00fa *Projects*, cliquear la opci\u00f3n del proyecto creado en [Creaci\u00f3n del proyecto](#2.4-Creaci\u00f3n-del-proyecto).\n2. Cliquear en la solapa *Assets*, y a la derecha del t\u00edtulo *Data assets*, cliquear el bot\u00f3n *New data asset*.\n3. Seleccionar solapa *Files*.\n4. Seleccionar todos los archivos CSV cargados en el *Cloud Object Storage*, cliquear en los tres puntos verticales y seleccionar la opci\u00f3n *Add as data asset*.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 5.3 Uso de Data Refinery\n1. En el men\u00fa *Projects*, cliquear la opci\u00f3n del proyecto creado en [Creaci\u00f3n del proyecto](#2.4-Creaci\u00f3n-del-proyecto).\n2. Cliquear en la solapa *Assets*, y a la derecha del t\u00edtulo *Data flows*, cliquear el bot\u00f3n *New data flow*.\n3. Seleccionar archivo *user_data.csv*.\n4. Cliquear el bot\u00f3n *Add*.\n5. **Demostraci\u00f3n en vivo**.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## 6. An\u00e1lisis y limpieza", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 6.1 Creaci\u00f3n del notebook\n1. En el men\u00fa *Projects*, cliquear la opci\u00f3n del proyecto creado en [Creaci\u00f3n del proyecto](#2.4-Creaci\u00f3n-del-proyecto).\n2. Cliquear en la solapa *Assets*, y a la derecha del t\u00edtulo *Notebooks*, cliquear el bot\u00f3n *New notebook*.\n3. Cliquear en la opci\u00f3n *Blank*.\n4. Especificar el nombre en el campo *Name*.\n5. Seleccionar el servicio de Spark creado en [Configuraci\u00f3n](#Configuraci\u00f3n) en el campo *Select runtime*.\n6. Cliquear el bot\u00f3n *Create Notebook*.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 6.2 Carga de datos en notebook\n1. Seleccionar la opci\u00f3n *Data* dentro del notebook (bot\u00f3n con 1 y 0 en la esquina superior derecha del notebook).\n2. En la solapa *Files*, cliquear el bot\u00f3n *Insert to code*, opci\u00f3n *Insert pandas DataFrame* del archivo *tweets_data.csv*.\n3. Ejecutar la celda de c\u00f3digo pegada (la celda se ejecuta utilizando el bot\u00f3n *Run* de la barra de herramientas).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 6.3 An\u00e1lisis y limpieza de datos\nDemostraci\u00f3n en vivo utilizando *pandas* y *Spark*.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## 7. Transformaci\u00f3n y enriquecimiento", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### 7.1 Enriquecimiento con Natural Language Understanding\n1. Agregar una nueva celda al notebook, pegar y ejecutar el siguiente comando: `!pip install --upgrade watson-developer-cloud`.\n2. Ingresar al *dashboard* de IBM Cloud: https://console.bluemix.net/dashboard/apps/.\n3. Seleccionar el servicio de *Natural Language Understanding*.\n3. Cliquear el men\u00fa *Service credentials*.\n4. Cliquear el bot\u00f3n *View credentials* de las credenciales creadas y copiar el JSON con los datos de acceso.\n5. Pegar el c\u00f3digo del JSON en una celda nueva y asignarlo a una variable de nombre `nlu_cred`.\n6. Ingresar a la [documentaci\u00f3n Natural Language Understanding](https://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/?python#api-explorer).\n7. Seleccionar el lenguaje de programaci\u00f3n *Python*, copiar el *Example request* y hacerlo funcionar.\n8. Copiar la siguiente funci\u00f3n para aplicar a la columna `tweet_text`. **Demostraci\u00f3n en vivo**.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "import json\nfrom watson_developer_cloud import NaturalLanguageUnderstandingV1\nfrom watson_developer_cloud.natural_language_understanding_v1 \\\n  import Features, EntitiesOptions, KeywordsOptions, SentimentOptions\n\nnatural_language_understanding = NaturalLanguageUnderstandingV1(\n  username=nlu['username'],\n  password=nlu['password'],\n  version='2018-03-16')\n\ndef get_sentiment(tweet_text):\n    try:\n        response = natural_language_understanding.analyze(\n            text=tweet_text,\n            features=Features(\n                sentiment=SentimentOptions()\n            )\n        )\n        return response['sentiment']['document']['label']\n    except Exception:\n        print(tweet_text)\n        return ''", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## 8. Modelado y puesta en producci\u00f3n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "\u00bfObtendr\u00e9 buenos resultados si quiero predecir cu\u00e1ntas personas me van a seguir en Twitter? *No*.\n\nDemostraci\u00f3n de uso de **Watson Machine Learning**.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## 9. Visualizaci\u00f3n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "1. En el men\u00fa *Projects*, cliquear la opci\u00f3n del proyecto creado en [Creaci\u00f3n del proyecto](#2.4-Creaci\u00f3n-del-proyecto).\n2. Cliquear en la solapa *Assets*, y a la derecha del t\u00edtulo *Dashboards*, cliquear el bot\u00f3n *New dashboard*.\n3. **Demostraci\u00f3n en vivo**.", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}